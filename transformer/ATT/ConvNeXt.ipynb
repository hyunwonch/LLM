{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pLXm3_uYEmHiXOy6D8Lvgm0lHY3PqWA_","timestamp":1684389641917}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torchvision.ops.misc import Permute\n","from torchvision.ops import StochasticDepth"],"metadata":{"id":"ygUactBbDL4f","executionInfo":{"status":"ok","timestamp":1748010705428,"user_tz":-540,"elapsed":10,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class CNBlock(nn.Module):\n","    def __init__(self, in_channels, layer_scale, stochastic_depth_prob):\n","        super().__init__()\n","\n","        self.residual = nn.Sequential(nn.Conv2d(in_channels, in_channels, 7, padding=3, groups=in_channels), # torchvision 구현체 보면 bias=True\n","                                      Permute([0, 2, 3, 1]), # 개채행열 -> 개행열채\n","                                      nn.LayerNorm(in_channels, eps=1e-6), # pixel-wise로 채널 축의 값들을 이용해서 normalize 하는 것\n","                                      # nn.LayerNorm 은 평균, 분산을 \"last D dimensions\" 에 대해 구한다.\n","                                      # 예를 들어, x = torch.randn(개, 채, 행, 열) 라면 layer_norm = nn.LayerNorm([채, 행, 열]) 이렇게 주면\n","                                      # 채,행,열 에 대해서 평균, 분산 구하는 데 참여시킨다는 뜻\n","                                      # 그러나 [개, 행, 열] 이런 식으로 건너뛸 순 없다! 따라서 채널 축의 값들만 이용하고 싶다면 Permute 해줘야\n","                                      Permute([0, 3, 1, 2]), # 개행열채 -> 개채행열\n","                                      nn.Conv2d(in_channels, 4 * in_channels, 1),\n","                                      nn.GELU(),\n","                                      nn.Conv2d(4 * in_channels, in_channels, 1))\n","        self.layer_scale = nn.Parameter(torch.ones(1,in_channels, 1, 1) * layer_scale)\n","        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n","\n","    def forward(self, x):\n","        residual = self.layer_scale * self.residual(x) # 어떤 channel이 중요한지를 학습시키자 (SE Net 아이디어 비슷)\n","        residual = self.stochastic_depth(residual)\n","        out = residual + x\n","        return out\n","\n","class ConvNeXt(nn.Module):\n","    def __init__(self, block_setting, stochastic_depth_prob = 0.0, layer_scale = 1e-6, num_classes = 1000, **kwargs):\n","        super().__init__()\n","\n","        layers = []\n","        layers += [nn.Sequential(nn.Conv2d(3, block_setting[0][0], kernel_size=4, stride=4),\n","                                 Permute([0, 2, 3, 1]),\n","                                 nn.LayerNorm(block_setting[0][0], eps=1e-6),\n","                                 Permute([0, 3, 1, 2]))]\n","\n","        total_stage_blocks = sum([setting[2] for setting in block_setting])\n","        stage_block_id = 0\n","        for in_channels, out_channels, num_blocks in block_setting:\n","            stage = []\n","            for _ in range(num_blocks):\n","                sd_prob = stochastic_depth_prob * stage_block_id / (total_stage_blocks - 1) # 1 빼야 마지막 블록이 설정한 stochastic_depth_prob을 가지게 된다.\n","                stage.append(CNBlock(in_channels, layer_scale, sd_prob))\n","                stage_block_id += 1\n","            layers += [nn.Sequential(*stage)]\n","            if out_channels is not None:\n","                downsample = nn.Sequential(Permute([0, 2, 3, 1]),\n","                                           nn.LayerNorm(in_channels),\n","                                           Permute([0, 3, 1, 2]),\n","                                           nn.Conv2d(in_channels, out_channels, kernel_size=2, stride=2))\n","                layers += [downsample]\n","\n","        self.features = nn.Sequential(*layers)\n","\n","        # https://github.com/pytorch/vision/blob/main/torchvision/models/convnext.py#L160 참고\n","        # Swin과 달리 pre-activation이 아니라서 LN-GAP-fc 가 아님. 근데 GAP-fc 만 하기엔 마지막 LN이 멀어서 GAP-fc 사이에 LN을 추가한 듯\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.classifier = nn.Sequential(nn.LayerNorm(block_setting[-1][0]),\n","                                        nn.Linear(block_setting[-1][0], num_classes))\n","\n","        for m in self.modules():\n","            if isinstance(m, (nn.Conv2d, nn.Linear)):\n","                nn.init.trunc_normal_(m.weight, std=0.02) # 논문엔 0.2 라 나와있는데 torchvision 코드는 0.02로 되어있음. 참고: https://github.com/pytorch/vision/blob/main/torchvision/models/convnext.py#L165\n","                # timm 코드도 0.02 로 되어있어서 코드도 0.02로 반영. 참고: https://github.com/huggingface/pytorch-image-models/blob/4d9c3ae2fb7cc4739ec57d4c06254d2ffc7e2c89/timm/models/convnext.py#L380\n","                # head init scale 은 fine-tuning 때 하는 것이므로 여기선 생략. 적용 코드 참고: https://github.com/huggingface/pytorch-image-models/blob/4d9c3ae2fb7cc4739ec57d4c06254d2ffc7e2c89/timm/models/convnext.py#L383\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"t1n_VkKJC66-","executionInfo":{"status":"ok","timestamp":1748010705472,"user_tz":-540,"elapsed":39,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def ConvNeXt_T(**kwargs):\n","    block_setting = [[96, 192, 3], # 192는 sep. d.s. conv에서 patch merging 따라하기 위해 똑같이 임베딩 차원 두 배 하는 것\n","                     [192, 384, 3],\n","                     [384, 768, 9],\n","                     [768, None, 3]]\n","    return ConvNeXt(block_setting, stochastic_depth_prob = 0.1,  **kwargs)\n","\n","def ConvNeXt_S(**kwargs):\n","    block_setting = [[96, 192, 3],\n","                     [192, 384, 3],\n","                     [384, 768, 27],\n","                     [768, None, 3]]\n","    return ConvNeXt(block_setting, stochastic_depth_prob = 0.4, **kwargs)\n","\n","def ConvNeXt_B(**kwargs):\n","    block_setting = [[128, 256, 3],\n","                     [256, 512, 3],\n","                     [512, 1024, 27],\n","                     [1024, None, 3]]\n","    return ConvNeXt(block_setting, stochastic_depth_prob = 0.5, **kwargs)\n","\n","def ConvNeXt_L(**kwargs):\n","    block_setting = [[192, 384, 3],\n","                     [384, 768, 3],\n","                     [768, 1536, 27],\n","                     [1536, None, 3]]\n","    return ConvNeXt(block_setting, stochastic_depth_prob = 0.5, **kwargs)"],"metadata":{"id":"Dg1kW2SVELbK","executionInfo":{"status":"ok","timestamp":1748010705528,"user_tz":-540,"elapsed":54,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model = ConvNeXt_L()\n","# print(model)\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model, input_size=(2,3,224,224), device='cpu')"],"metadata":{"id":"PA2-KLar_wKa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748010717529,"user_tz":-540,"elapsed":11995,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"d0d57d11-7137-43c9-8cc5-f716cc197657"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]},{"output_type":"execute_result","data":{"text/plain":["===============================================================================================\n","Layer (type:depth-idx)                        Output Shape              Param #\n","===============================================================================================\n","ConvNeXt                                      [2, 1000]                 --\n","├─Sequential: 1-1                             [2, 1536, 7, 7]           --\n","│    └─Sequential: 2-1                        [2, 192, 56, 56]          --\n","│    │    └─Conv2d: 3-1                       [2, 192, 56, 56]          9,408\n","│    │    └─Permute: 3-2                      [2, 56, 56, 192]          --\n","│    │    └─LayerNorm: 3-3                    [2, 56, 56, 192]          384\n","│    │    └─Permute: 3-4                      [2, 192, 56, 56]          --\n","│    └─Sequential: 2-2                        [2, 192, 56, 56]          --\n","│    │    └─CNBlock: 3-5                      [2, 192, 56, 56]          306,048\n","│    │    └─CNBlock: 3-6                      [2, 192, 56, 56]          306,048\n","│    │    └─CNBlock: 3-7                      [2, 192, 56, 56]          306,048\n","│    └─Sequential: 2-3                        [2, 384, 28, 28]          --\n","│    │    └─Permute: 3-8                      [2, 56, 56, 192]          --\n","│    │    └─LayerNorm: 3-9                    [2, 56, 56, 192]          384\n","│    │    └─Permute: 3-10                     [2, 192, 56, 56]          --\n","│    │    └─Conv2d: 3-11                      [2, 384, 28, 28]          295,296\n","│    └─Sequential: 2-4                        [2, 384, 28, 28]          --\n","│    │    └─CNBlock: 3-12                     [2, 384, 28, 28]          1,201,920\n","│    │    └─CNBlock: 3-13                     [2, 384, 28, 28]          1,201,920\n","│    │    └─CNBlock: 3-14                     [2, 384, 28, 28]          1,201,920\n","│    └─Sequential: 2-5                        [2, 768, 14, 14]          --\n","│    │    └─Permute: 3-15                     [2, 28, 28, 384]          --\n","│    │    └─LayerNorm: 3-16                   [2, 28, 28, 384]          768\n","│    │    └─Permute: 3-17                     [2, 384, 28, 28]          --\n","│    │    └─Conv2d: 3-18                      [2, 768, 14, 14]          1,180,416\n","│    └─Sequential: 2-6                        [2, 768, 14, 14]          --\n","│    │    └─CNBlock: 3-19                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-20                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-21                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-22                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-23                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-24                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-25                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-26                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-27                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-28                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-29                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-30                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-31                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-32                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-33                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-34                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-35                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-36                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-37                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-38                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-39                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-40                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-41                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-42                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-43                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-44                     [2, 768, 14, 14]          4,763,136\n","│    │    └─CNBlock: 3-45                     [2, 768, 14, 14]          4,763,136\n","│    └─Sequential: 2-7                        [2, 1536, 7, 7]           --\n","│    │    └─Permute: 3-46                     [2, 14, 14, 768]          --\n","│    │    └─LayerNorm: 3-47                   [2, 14, 14, 768]          1,536\n","│    │    └─Permute: 3-48                     [2, 768, 14, 14]          --\n","│    │    └─Conv2d: 3-49                      [2, 1536, 7, 7]           4,720,128\n","│    └─Sequential: 2-8                        [2, 1536, 7, 7]           --\n","│    │    └─CNBlock: 3-50                     [2, 1536, 7, 7]           18,963,456\n","│    │    └─CNBlock: 3-51                     [2, 1536, 7, 7]           18,963,456\n","│    │    └─CNBlock: 3-52                     [2, 1536, 7, 7]           18,963,456\n","├─AdaptiveAvgPool2d: 1-2                      [2, 1536, 1, 1]           --\n","├─Sequential: 1-3                             [2, 1000]                 --\n","│    └─LayerNorm: 2-9                         [2, 1536]                 3,072\n","│    └─Linear: 2-10                           [2, 1000]                 1,537,000\n","===============================================================================================\n","Total params: 197,767,336\n","Trainable params: 197,767,336\n","Non-trainable params: 0\n","Total mult-adds (Units.GIGABYTES): 68.81\n","===============================================================================================\n","Input size (MB): 1.20\n","Forward/backward pass size (MB): 828.55\n","Params size (MB): 790.96\n","Estimated Total Size (MB): 1620.71\n","==============================================================================================="]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["x = torch.randn(2,3,224,224)\n","print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TNV93Y-_wVK","executionInfo":{"status":"ok","timestamp":1748010722123,"user_tz":-540,"elapsed":4532,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"5b17fe67-f262-4063-ef14-5c93b9f77e9e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1000])\n"]}]},{"cell_type":"code","source":["# Layer scale 기법에 대해\n","class MyModel(nn.Module):\n","    def __init__(self, in_channels, layer_scale):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n","        self.layer_scale = nn.Parameter(torch.ones(1, in_channels, 1, 1) * layer_scale)\n","\n","    def forward(self, x):\n","        out = self.conv(x)\n","        print(out.shape)\n","        print(self.layer_scale.shape)\n","        print(self.layer_scale)\n","        print(out)\n","        out = out * self.layer_scale  # Apply layer scaling (broadcasting)\n","        print(out)\n","        return out\n","\n","model = MyModel(in_channels=2, layer_scale=0.5)\n","y=model(torch.randn(1, 2, 4, 4))\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwhyyn7xrQVe","executionInfo":{"status":"ok","timestamp":1748010722191,"user_tz":-540,"elapsed":62,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"7b50787c-85e8-47e4-af67-b95f354ad40f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 4, 4])\n","torch.Size([1, 2, 1, 1])\n","Parameter containing:\n","tensor([[[[0.5000]],\n","\n","         [[0.5000]]]], requires_grad=True)\n","tensor([[[[ 0.0205,  0.3084,  0.3084,  0.5715],\n","          [-0.0061,  0.5617,  0.5617,  1.1278],\n","          [-0.0061,  0.5617,  0.5617,  1.1278],\n","          [ 0.2057,  0.7788,  0.7788,  1.1372]],\n","\n","         [[ 0.4279, -0.0342, -0.0342, -0.2843],\n","          [ 0.2425, -0.1454, -0.1454, -0.2460],\n","          [ 0.2425, -0.1454, -0.1454, -0.2460],\n","          [ 0.3192,  0.0039,  0.0039, -0.1718]]]],\n","       grad_fn=<ConvolutionBackward0>)\n","tensor([[[[ 0.0103,  0.1542,  0.1542,  0.2857],\n","          [-0.0030,  0.2809,  0.2809,  0.5639],\n","          [-0.0030,  0.2809,  0.2809,  0.5639],\n","          [ 0.1029,  0.3894,  0.3894,  0.5686]],\n","\n","         [[ 0.2139, -0.0171, -0.0171, -0.1421],\n","          [ 0.1213, -0.0727, -0.0727, -0.1230],\n","          [ 0.1213, -0.0727, -0.0727, -0.1230],\n","          [ 0.1596,  0.0019,  0.0019, -0.0859]]]], grad_fn=<MulBackward0>)\n","torch.Size([1, 2, 4, 4])\n"]}]},{"cell_type":"code","source":["# Layer norm, 각 픽셀 위치 마다, 채널 축에 대해서 샘플의 평균, 분산 구하려면?\n","x = torch.randn(2, 3, 2, 2)\n","ln = nn.LayerNorm(3, eps=1e-5)\n","y = ln(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n","print(\"After LayerNorm: \", y) # 각 픽셀 위치에서 채널 축으로 평균 0 분산 1 이 되도록 함\n","print(\"weight shape: \", ln.weight.shape)"],"metadata":{"id":"6eHPmBAuuDMk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748010722231,"user_tz":-540,"elapsed":36,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"9c58642a-d6da-4692-db93-f5cce020569f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["After LayerNorm:  tensor([[[[-1.1600,  0.1625],\n","          [ 0.9776,  0.6300]],\n","\n","         [[ 1.2806,  1.1354],\n","          [ 0.3957, -1.4115]],\n","\n","         [[-0.1205, -1.2979],\n","          [-1.3733,  0.7815]]],\n","\n","\n","        [[[-0.3606,  0.1804],\n","          [-1.4109,  1.0528]],\n","\n","         [[-1.0039, -1.3049],\n","          [ 0.6233,  0.2913]],\n","\n","         [[ 1.3645,  1.1246],\n","          [ 0.7876, -1.3441]]]], grad_fn=<PermuteBackward0>)\n","weight shape:  torch.Size([3])\n"]}]},{"cell_type":"code","source":["# Layer norm, 각 픽셀 위치 마다, 채널 축에 대해서 하려면? (직접 구하기)\n","mean = x.mean(dim=1, keepdim=True)\n","std = x.std(dim=1, keepdim=True, unbiased=False)\n","print(mean.shape)\n","print(std.shape)\n","y_manual = (x - mean) / (std + 1e-5)\n","print(\"Manual normalization: \", y_manual)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sKN-oY0wGhT","executionInfo":{"status":"ok","timestamp":1748010722246,"user_tz":-540,"elapsed":12,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"91f9c6b2-e31f-477e-94dc-201cf04b7e03"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1, 2, 2])\n","torch.Size([2, 1, 2, 2])\n","Manual normalization:  tensor([[[[-1.1600,  0.1625],\n","          [ 0.9778,  0.6300]],\n","\n","         [[ 1.2805,  1.1354],\n","          [ 0.3958, -1.4115]],\n","\n","         [[-0.1205, -1.2979],\n","          [-1.3736,  0.7815]]],\n","\n","\n","        [[[-0.3606,  0.1804],\n","          [-1.4110,  1.0528]],\n","\n","         [[-1.0039, -1.3049],\n","          [ 0.6233,  0.2913]],\n","\n","         [[ 1.3645,  1.1245],\n","          [ 0.7877, -1.3441]]]])\n"]}]},{"cell_type":"code","source":["# 배치놈은 어땟나\n","x = torch.randn(2, 3, 2, 2)\n","bn = nn.BatchNorm2d(3, eps=1e-5) # BN은 반대로 3에 해당하는 '채' 제외, '개행열'에 대해 평균 분산 구하는 것으로 구현되어 있다\n","y_bn = bn(x)\n","print(\"After BatchNorm2d: \", y_bn)\n","print(\"weight shape: \", bn.weight.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzzqdBMf1qX0","executionInfo":{"status":"ok","timestamp":1748010722311,"user_tz":-540,"elapsed":46,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"4c3e23bb-0707-4aa2-9692-31feee635d5b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["After BatchNorm2d:  tensor([[[[ 0.2045,  1.1235],\n","          [-1.4211,  0.1841]],\n","\n","         [[ 0.2215,  0.4723],\n","          [ 1.8592, -1.3537]],\n","\n","         [[ 1.0293,  0.4474],\n","          [ 1.3295, -1.1833]]],\n","\n","\n","        [[[ 0.9182,  0.7681],\n","          [ 0.0142, -1.7914]],\n","\n","         [[-0.5079, -1.2443],\n","          [-0.2132,  0.7662]],\n","\n","         [[ 0.8556, -1.5449],\n","          [-0.3716, -0.5620]]]], grad_fn=<NativeBatchNormBackward0>)\n","weight shape:  torch.Size([3])\n"]}]},{"cell_type":"code","source":["# 배치놈은 어땟나 (직접 구하기)\n","mean = x.mean(dim=(0, 2, 3), keepdim=True)\n","std = x.std(dim=(0, 2, 3), keepdim=True, unbiased=False)\n","print(mean.shape)\n","print(std.shape)\n","y_manual = (x - mean) / (std + 1e-5)\n","print(\"Manual Batch Normalization: \", y_manual)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0b2KdwmvwZc","executionInfo":{"status":"ok","timestamp":1748010722335,"user_tz":-540,"elapsed":22,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"973581cc-0ed0-43f0-89c0-73d009ee8872"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 3, 1, 1])\n","torch.Size([1, 3, 1, 1])\n","Manual Batch Normalization:  tensor([[[[ 0.2045,  1.1235],\n","          [-1.4211,  0.1841]],\n","\n","         [[ 0.2215,  0.4723],\n","          [ 1.8591, -1.3537]],\n","\n","         [[ 1.0293,  0.4474],\n","          [ 1.3295, -1.1833]]],\n","\n","\n","        [[[ 0.9182,  0.7681],\n","          [ 0.0142, -1.7914]],\n","\n","         [[-0.5079, -1.2443],\n","          [-0.2132,  0.7662]],\n","\n","         [[ 0.8556, -1.5449],\n","          [-0.3716, -0.5620]]]])\n"]}]},{"cell_type":"code","source":["# 흔히 알려진 layer norm 그림에선..\n","x = torch.randn(2, 3, 2, 2)\n","ln = nn.LayerNorm([3, 2, 2], eps=1e-5)\n","y = ln(x)\n","print(\"After LayerNorm: \", y)\n","print(\"weight shape: \", ln.weight.shape) # nn.LayerNorm([C,H,W]) 이면 C*H*W 개에 대해서 평균, 분산 내서 normalize 하는 거고 재배치할 평균, 분산도 각각 CHW 개다"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6RuYrolg2F5","executionInfo":{"status":"ok","timestamp":1748010722373,"user_tz":-540,"elapsed":13,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"ed2902a9-ebb8-44db-e713-c24a4cfc6834"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["After LayerNorm:  tensor([[[[-2.0943, -1.3114],\n","          [-0.9862,  0.1284]],\n","\n","         [[ 0.1934,  0.9875],\n","          [ 0.2357,  0.6703]],\n","\n","         [[-0.5168,  1.5059],\n","          [ 0.3218,  0.8657]]],\n","\n","\n","        [[[-0.0390,  0.0820],\n","          [ 0.0447,  0.3354]],\n","\n","         [[ 0.6128,  0.7946],\n","          [ 0.3978, -3.1131]],\n","\n","         [[-0.3371, -0.0195],\n","          [ 0.8816,  0.3597]]]], grad_fn=<NativeLayerNormBackward0>)\n","weight shape:  torch.Size([3, 2, 2])\n"]}]},{"cell_type":"code","source":["# 흔히 알려진 layer norm 그림에선.. (직접 구하기)\n","mean = x.mean(dim=(1, 2, 3), keepdim=True)\n","std = x.std(dim=(1, 2, 3), keepdim=True, unbiased=False)\n","print(mean.shape)\n","print(std.shape)\n","y_manual = (x - mean) / (std + 1e-5)\n","print(\"Manual normalization: \", y_manual)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9NIPFcuvj-M","executionInfo":{"status":"ok","timestamp":1748010722395,"user_tz":-540,"elapsed":20,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"ddafde37-ef0b-4123-f264-d8004d3a4769"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1, 1, 1])\n","torch.Size([2, 1, 1, 1])\n","Manual normalization:  tensor([[[[-2.0943, -1.3114],\n","          [-0.9862,  0.1284]],\n","\n","         [[ 0.1934,  0.9875],\n","          [ 0.2357,  0.6703]],\n","\n","         [[-0.5168,  1.5059],\n","          [ 0.3218,  0.8657]]],\n","\n","\n","        [[[-0.0390,  0.0820],\n","          [ 0.0447,  0.3354]],\n","\n","         [[ 0.6128,  0.7946],\n","          [ 0.3978, -3.1131]],\n","\n","         [[-0.3371, -0.0195],\n","          [ 0.8816,  0.3597]]]])\n"]}]},{"cell_type":"code","source":["# # 내 필기용\n","# from functools import partial\n","\n","# def power(base, exponent):\n","#     return base ** exponent\n","\n","# square = partial(power, 2)  # 밑을 2로 고정\n","# cube = partial(power, 3)  # 밑을 3으로 고정\n","\n","# print(square(4))  # 출력: 16 (2의 4제곱)\n","# print(cube(3))  # 출력: 27 (3의 3제곱)"],"metadata":{"id":"qy87RVMxKoJk","executionInfo":{"status":"ok","timestamp":1748010722399,"user_tz":-540,"elapsed":1,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}}},"execution_count":14,"outputs":[]}]}