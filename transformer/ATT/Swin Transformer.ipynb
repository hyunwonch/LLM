{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPsJo8FvcryZpHqi8UBHm57"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"lK2KjVJDzWHd","executionInfo":{"status":"ok","timestamp":1748005470680,"user_tz":-540,"elapsed":3514,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1cbafcf7-c7c9-401c-dc73-c35e23dac753"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"]}],"source":["import torch\n","import torch.nn.functional as F # for F.pad\n","from torch import nn\n","\n","from torchvision.ops.misc import Permute\n","from torchvision.ops import StochasticDepth\n","\n","import matplotlib.pyplot as plt\n","!pip install einops\n","from einops import rearrange"]},{"cell_type":"code","source":["# stochastic depth 에 대해\n","class test_model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.residual = nn.Conv2d(1,1,1, bias=False)\n","        self.stochastic_depth = StochasticDepth(0.3, \"row\") # 0.3이 죽일 확률 # \"row\"는 data 마다 다른 depth를 가지게 함!\n","\n","    def forward(self,x):\n","        residual = self.residual(x)\n","        residual = self.stochastic_depth(residual)\n","        return x + residual\n","\n","model=test_model()\n","x=torch.ones(2,1,2,2)\n","model.train()\n","print(model(x)) # 훈련 때는 1/(1-p) 을 residual에 곱한다\n","w=model.residual.weight.item()\n","print(round(1 + 1 * w/(1-0.3), 4))\n","\n","model.eval()\n","print(model(x))\n","print(round(1 + 1 * w, 4)) # 테스트는 무시하지 않고 통과시킨다.\n","# stochastic depth는 드랍아웃을 node가 아닌 residual block에 적용했다고 생각할 수 있다.\n","# residual=0 이면 그냥 통과인거니까 identity mapping임. 따라서 depth 가 stochastic하다!\n","# stochastic depth 논문에서는 훈련 때는 랜덤하게 skip하고 테스트 때는 다 통과하되 1-p를 곱하는 것으로 설명 되어있다.\n","# 하지만 토치 구현에서는 반대로 train 땐 1/(1-p) 를 곱하고 테스트 때는 그냥 통과하는 것으로 구현!\n","# 드랍아웃도 이처럼 논문과 달리 train 땐 1/(1-p) 로 키워놓고 테스트 때는 그대로 나오게끔 구현되어있음"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2Sj04MH-_4Z","executionInfo":{"status":"ok","timestamp":1748005470721,"user_tz":-540,"elapsed":15,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"2974e83d-5d93-43d5-f066-687573dc4d80"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[1.3137, 1.3137],\n","          [1.3137, 1.3137]]],\n","\n","\n","        [[[1.3137, 1.3137],\n","          [1.3137, 1.3137]]]], grad_fn=<AddBackward0>)\n","1.3137\n","tensor([[[[1.2196, 1.2196],\n","          [1.2196, 1.2196]]],\n","\n","\n","        [[[1.2196, 1.2196],\n","          [1.2196, 1.2196]]]], grad_fn=<AddBackward0>)\n","1.2196\n"]}]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","    def __init__(self, dim, d_ff, drop_p):\n","        super().__init__()\n","\n","        self.linear = nn.Sequential(nn.Linear(dim, d_ff),\n","                                    nn.GELU(),\n","                                    nn.Dropout(drop_p),\n","                                    nn.Linear(d_ff, dim))\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","        return x\n","\n","class PatchMerging(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","\n","        self.dim = dim\n","        self.norm = nn.LayerNorm(4*dim, eps=1e-5)\n","        self.reduction = nn.Linear(4*dim, 2*dim, bias=False) # merging 할 때 torch.cat으로 channel 축으로 쌓기 때문에 4dim이 된다\n","\n","    def forward(self, x): # 개행열채\n","        H, W, _ = x.shape[1:]\n","        x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2)) # 홀수면 한줄 패딩 시킴, 채행열 기준 lr tb front back 순 이므로 행열채에 대해서는 front back lr tb 가 된다\n","        x0 = x[..., 0::2, 0::2, :]  # 1행 1열들\n","        x1 = x[..., 1::2, 0::2, :]  # 2행 1열들\n","        x2 = x[..., 0::2, 1::2, :]  # 1행 2열들\n","        x3 = x[..., 1::2, 1::2, :]  # 2행 2열들\n","        x = torch.cat([x0, x1, x2, x3], -1)  # 개 행/2 열/2 4채\n","\n","        x = self.norm(x) # concat 하고 나서 바로 LN 하므로 (즉, 2x2 묶고 + channel 축 으로 normalization 한다) conv 로는 구현이 불가능! 그래서 nn.Linear로\n","        x = self.reduction(x)  # 개 행/2 열/2 2채\n","        return x\n","\n","class ShiftedWindowAttention(nn.Module):\n","    def __init__(self, dim, window_size, shift_size, num_heads, drop_p = 0.0):\n","        super().__init__()\n","\n","        self.window_size = window_size\n","        self.shift_size = shift_size\n","        self.num_heads = num_heads\n","\n","        self.fc_q = nn.Linear(dim, dim)\n","        self.fc_k = nn.Linear(dim, dim)\n","        self.fc_v = nn.Linear(dim, dim)\n","        self.fc_o = nn.Linear(dim, dim)\n","\n","        self.scale = torch.sqrt(torch.tensor(dim / num_heads))\n","\n","        self.get_relative_position_bias()\n","\n","    def get_relative_position_bias(self):\n","\n","        B_hat = nn.Parameter(torch.zeros(self.num_heads, (2 * self.window_size[0] - 1), (2 * self.window_size[1] - 1)))\n","        nn.init.trunc_normal_(B_hat, std=0.02)\n","\n","        coords_h = torch.arange(self.window_size[0])\n","        coords_w = torch.arange(self.window_size[1])\n","        H, W = torch.meshgrid(coords_h, coords_w)\n","\n","        relative_coords_h = H.reshape(1,-1) - H.reshape(-1,1)\n","        relative_coords_w = W.reshape(1,-1) - W.reshape(-1,1)\n","        relative_position_index_h = relative_coords_h + self.window_size[0] - 1 # 인덱스가 0부터 시작하도록 6을 더해줌 (즉, \"기준\"의 좌표는 (6,6)임)\n","        relative_position_index_w = relative_coords_w + self.window_size[1] - 1\n","\n","        self.B = B_hat[:, relative_position_index_h, relative_position_index_w]\n","        self.B = self.B.unsqueeze(0).unsqueeze(0)\n","\n","    def forward(self, x):\n","\n","        M0, M1 = self.window_size\n","        B, H, W, C = x.shape # 개행열채\n","\n","        # window size의 배수가 되도록 padding\n","        pad_r = (M1 - W % M1) % M1\n","        pad_b = (M0 - H % M0) % M0\n","        x = F.pad(x, (0, 0, 0, pad_r, 0, pad_b)) # 채행열 기준 lr tb front back 순 이므로 행열채에 대해서는 front back lr tb 가 된다\n","        _, H_pad, W_pad, _ = x.shape\n","\n","        # down sample 많이 돼서 window size보다 resolution이 더 작으면 shift 할 필요 없음\n","        shift_size = self.shift_size.copy()\n","        if H_pad <= M0:\n","            shift_size[0] = 0\n","        if W_pad <= M1:\n","            shift_size[1] = 0\n","\n","        # cyclic shift\n","        if sum(shift_size) > 0:\n","            x = torch.roll(x, shifts=(-shift_size[0], -shift_size[1]), dims=(1, 2))\n","\n","        # MSA\n","        x = rearrange(x, '개 (윈0 M0) (윈1 M1) 차 -> 개 (윈0 윈1) (M0 M1) 차', M0=M0, M1=M1) # 개행(21)열(21)채 -> 개윈(9)단(49)차\n","\n","        Q = self.fc_q(x) # 개윈(9)단(49)차\n","        K = self.fc_k(x)\n","        V = self.fc_v(x)\n","\n","        Q = rearrange(Q, '개 윈 단 (헤 차) -> 개 윈 헤 단 차', 헤 = self.num_heads) # 개윈단차 -> 개윈헤단차\n","        K = rearrange(K, '개 윈 단 (헤 차) -> 개 윈 헤 단 차', 헤 = self.num_heads)\n","        V = rearrange(V, '개 윈 단 (헤 차) -> 개 윈 헤 단 차', 헤 = self.num_heads)\n","\n","        attn = Q @ K.transpose(-2,-1)/self.scale # 개윈헤단단\n","\n","        # add relative position bias\n","        attn = attn + self.B\n","\n","        # generate attention mask\n","        if sum(shift_size) > 0:\n","            window_group_num = x.new_zeros(H_pad, W_pad) # x와 같은 데이터 타입과 디바이스에 올려진, H_pad 행 x W_pad 열인 행렬을 만듦\n","            h_slices = ((0, -M0), (-M0, -shift_size[0]), (-shift_size[0], None))\n","            w_slices = ((0, -M1), (-M1, -shift_size[1]), (-shift_size[1], None))\n","            count = 0\n","            for h in h_slices:\n","                for w in w_slices:\n","                    window_group_num[h[0] : h[1], w[0] : w[1]] = count\n","                    count += 1\n","            window_group_num = rearrange(window_group_num, '(윈0 M0) (윈1 M1) -> (윈0 윈1) (M0 M1)', M0=M0, M1=M1)\n","            attn_mask = window_group_num.unsqueeze(2) - window_group_num.unsqueeze(1) # 9 x 49 x 49\n","            attn_mask[attn_mask != 0] = -1e10\n","            attn = attn + attn_mask.unsqueeze(1).unsqueeze(0) # + 1 9 1 49 49\n","\n","        attn = F.softmax(attn, dim=-1) # 개윈헤단단\n","\n","        attn = attn @ V # 개윈헤단차\n","\n","        x = rearrange(attn, '개 윈 헤 단 차 -> 개 윈 단 (헤 차)') # 개윈헤단차 -> 개윈단차\n","        x = self.fc_o(x) # 개윈단차\n","\n","        x = rearrange(x, '개 (윈0 윈1) (M0 M1) 차 -> 개 (윈0 M0) (윈1 M1) 차', 윈0=H_pad//M0, M0=M0) # 개윈(9)단(49)차 -> 개행(21)열(21)채\n","\n","        # reverse cyclic shift\n","        if sum(shift_size) > 0:\n","            x = torch.roll(x, shifts=(shift_size[0], shift_size[1]), dims=(1, 2))\n","\n","        # unpad features\n","        x = x[:, :H, :W, :]\n","\n","        return x\n","\n","class SwinTransformerBlock(nn.Module):\n","    def __init__(self, dim, num_heads, window_size, shift_size, mlp_ratio = 4.0, drop_p = 0.0, stochastic_depth_prob = 0.0):\n","        super().__init__()\n","\n","        self.SW_MSA_LN = nn.LayerNorm(dim, eps=1e-5)\n","        self.SW_MSA = ShiftedWindowAttention(dim, window_size, shift_size, num_heads, drop_p=drop_p)\n","\n","        self.FF_LN = nn.LayerNorm(dim, eps=1e-5)\n","        self.FF = FeedForward(dim, int(dim * mlp_ratio), drop_p=drop_p)\n","\n","        self.dropout = nn.Dropout(drop_p)\n","        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n","\n","        # 초기화는 https://github.com/pytorch/vision/blob/main/torchvision/models/swin_transformer.py#L446 참고\n","        for m in self.FF.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.normal_(m.bias, std=1e-6)\n","\n","    def forward(self, x):\n","\n","        residual = self.SW_MSA_LN(x)\n","        residual = self.SW_MSA(residual)\n","        residual = self.dropout(residual)\n","        residual = self.stochastic_depth(residual)\n","        x = x + residual\n","\n","        residual = self.FF_LN(x)\n","        residual = self.FF(residual)\n","        residual = self.dropout(residual)\n","        residual = self.stochastic_depth(residual)\n","        x = x + residual\n","\n","        return x\n","\n","class SwinTransformer(nn.Module):\n","    def __init__(self, patch_size, embed_dim, depths, num_heads, window_size, mlp_ratio = 4, drop_p = 0.0, stochastic_depth_prob = 0.1, num_classes = 1000):\n","        super().__init__()\n","\n","        self.num_classes = num_classes\n","\n","        layers = []\n","        # split image into non-overlapping patches\n","        layers += [nn.Sequential(nn.Conv2d(3, embed_dim, kernel_size=(patch_size[0], patch_size[1]), stride=(patch_size[0], patch_size[1])),\n","                                 Permute([0, 2, 3, 1]), # 여기서 개행열채로 바뀜. torch.permute() 를 쓰려면 forward 에서 해야하기 때문에 nn.Sequential() 안에 넣으려면 이렇게!\n","                                 nn.LayerNorm(embed_dim, eps=1e-5))]\n","                                 # https://github.com/pytorch/vision/blob/main/torchvision/models/swin_transformer.py#L561 여기 보면 norm 하고 block에서 또 norm 함\n","\n","        total_stage_blocks = sum(depths)\n","        stage_block_id = 0\n","        # build SwinTransformer blocks\n","        for i_stage in range(len(depths)):\n","            stage = []\n","            dim = embed_dim * 2**i_stage\n","            for i_layer in range(depths[i_stage]):\n","                # adjust stochastic depth probability based on the depth of the stage block\n","                sd_prob = stochastic_depth_prob * stage_block_id / (total_stage_blocks - 1)\n","                stage += [SwinTransformerBlock(dim,\n","                                               num_heads[i_stage],\n","                                               window_size=window_size,\n","                                               shift_size=[0 if i_layer % 2 == 0 else w // 2 for w in window_size], # 한 번은 W-MSA, 한 번은 SW-MSA\n","                                               mlp_ratio=mlp_ratio,\n","                                               drop_p = drop_p,\n","                                               stochastic_depth_prob=sd_prob)]\n","                stage_block_id += 1\n","            layers += [nn.Sequential(*stage)]\n","            # add patch merging layer\n","            # https://github.com/pytorch/vision/blob/main/torchvision/models/swin_transformer.py#L590 참고\n","            # Stage 구성이 그림에서 Partition - [[ Linear Embedding - Swin Block ]] 이렇게 묶여있는데 코드에서는\n","            # 첫 conv - [[ Swin Block - Path Merging ]] 이렇게 묶이게끔 짜여져 있다)\n","            if i_stage < (len(depths) - 1):\n","                layers += [PatchMerging(dim)]\n","        self.features = nn.Sequential(*layers)\n","\n","        # https://github.com/pytorch/vision/blob/main/torchvision/models/swin_transformer.py#L595 참고\n","        # LN - GAP - fc 로 되어있음.\n","        # ViT의 실험 중 CLS 토큰 안 쓰고 최종 인코더 아웃풋에 LN-GAP-fc 하는 방식을 Swin 에서는 기본 구조로 채택함!\n","        self.norm = nn.LayerNorm(dim, eps=1e-5)\n","        self.avgpool = nn.Sequential(Permute([0, 3, 1, 2]), # 개행열채 -> 개채행열\n","                                     nn.AdaptiveAvgPool2d((1,1)))\n","        self.fc = nn.Linear(dim, num_classes)\n","\n","        # 초기화는 https://github.com/pytorch/vision/blob/main/torchvision/models/swin_transformer.py#L601 참고\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.trunc_normal_(m.weight, std=0.02)\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.norm(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, start_dim=1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"4EsYhRAszXqK","executionInfo":{"status":"ok","timestamp":1748005470858,"user_tz":-540,"elapsed":135,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def swin_t(**kwargs): # 28288354\n","    return SwinTransformer(patch_size=[4, 4], embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24], window_size=[7, 7], stochastic_depth_prob=0.2, **kwargs)\n","\n","def swin_s(**kwargs): # 49606258\n","    return SwinTransformer(patch_size=[4, 4], embed_dim=96, depths=[2, 2, 18, 2], num_heads=[3, 6, 12, 24], window_size=[7, 7], stochastic_depth_prob=0.3, **kwargs)\n","\n","def swin_b(**kwargs): # 87768224\n","    return SwinTransformer(patch_size=[4, 4], embed_dim=128, depths=[2, 2, 18, 2], num_heads=[4, 8, 16, 32], window_size=[7, 7], stochastic_depth_prob=0.5, **kwargs)\n","\n","def swin_l(**kwargs):\n","    return SwinTransformer(patch_size=[4, 4], embed_dim=192, depths=[2, 2, 18, 2], num_heads=[6, 12, 24, 48], window_size=[7, 7], stochastic_depth_prob=0.6, **kwargs)"],"metadata":{"id":"z37TO47AfUxj","executionInfo":{"status":"ok","timestamp":1748005470873,"user_tz":-540,"elapsed":26,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = swin_l()\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model, input_size=(2,3,224,224), device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hpd76Z5ffZy6","executionInfo":{"status":"ok","timestamp":1748005482881,"user_tz":-540,"elapsed":12013,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"46fd97ae-20e7-4bda-ce8d-57897868650a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]},{"output_type":"execute_result","data":{"text/plain":["====================================================================================================\n","Layer (type:depth-idx)                             Output Shape              Param #\n","====================================================================================================\n","SwinTransformer                                    [2, 1000]                 --\n","├─Sequential: 1-1                                  [2, 7, 7, 1536]           --\n","│    └─Sequential: 2-1                             [2, 56, 56, 192]          --\n","│    │    └─Conv2d: 3-1                            [2, 192, 56, 56]          9,408\n","│    │    └─Permute: 3-2                           [2, 56, 56, 192]          --\n","│    │    └─LayerNorm: 3-3                         [2, 56, 56, 192]          384\n","│    └─Sequential: 2-2                             [2, 56, 56, 192]          --\n","│    │    └─SwinTransformerBlock: 3-4              [2, 56, 56, 192]          444,864\n","│    │    └─SwinTransformerBlock: 3-5              [2, 56, 56, 192]          444,864\n","│    └─PatchMerging: 2-3                           [2, 28, 28, 384]          --\n","│    │    └─LayerNorm: 3-6                         [2, 28, 28, 768]          1,536\n","│    │    └─Linear: 3-7                            [2, 28, 28, 384]          294,912\n","│    └─Sequential: 2-4                             [2, 28, 28, 384]          --\n","│    │    └─SwinTransformerBlock: 3-8              [2, 28, 28, 384]          1,774,464\n","│    │    └─SwinTransformerBlock: 3-9              [2, 28, 28, 384]          1,774,464\n","│    └─PatchMerging: 2-5                           [2, 14, 14, 768]          --\n","│    │    └─LayerNorm: 3-10                        [2, 14, 14, 1536]         3,072\n","│    │    └─Linear: 3-11                           [2, 14, 14, 768]          1,179,648\n","│    └─Sequential: 2-6                             [2, 14, 14, 768]          --\n","│    │    └─SwinTransformerBlock: 3-12             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-13             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-14             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-15             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-16             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-17             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-18             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-19             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-20             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-21             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-22             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-23             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-24             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-25             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-26             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-27             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-28             [2, 14, 14, 768]          7,087,872\n","│    │    └─SwinTransformerBlock: 3-29             [2, 14, 14, 768]          7,087,872\n","│    └─PatchMerging: 2-7                           [2, 7, 7, 1536]           --\n","│    │    └─LayerNorm: 3-30                        [2, 7, 7, 3072]           6,144\n","│    │    └─Linear: 3-31                           [2, 7, 7, 1536]           4,718,592\n","│    └─Sequential: 2-8                             [2, 7, 7, 1536]           --\n","│    │    └─SwinTransformerBlock: 3-32             [2, 7, 7, 1536]           28,331,520\n","│    │    └─SwinTransformerBlock: 3-33             [2, 7, 7, 1536]           28,331,520\n","├─LayerNorm: 1-2                                   [2, 7, 7, 1536]           3,072\n","├─Sequential: 1-3                                  [2, 1536, 1, 1]           --\n","│    └─Permute: 2-9                                [2, 1536, 7, 7]           --\n","│    └─AdaptiveAvgPool2d: 2-10                     [2, 1536, 1, 1]           --\n","├─Linear: 1-4                                      [2, 1000]                 1,537,000\n","====================================================================================================\n","Total params: 196,437,160\n","Trainable params: 196,437,160\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 451.86\n","====================================================================================================\n","Input size (MB): 1.20\n","Forward/backward pass size (MB): 867.06\n","Params size (MB): 785.75\n","Estimated Total Size (MB): 1654.01\n","===================================================================================================="]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["x = torch.randn(2,3,224,224)\n","print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrCJ0MDI9gx9","executionInfo":{"status":"ok","timestamp":1748005486927,"user_tz":-540,"elapsed":4044,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"f47a4e90-c7cd-4c84-9bf9-d2a271898c21"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1000])\n"]}]},{"cell_type":"code","source":["model.train()\n","print(model(x))\n","print(model(x))\n","model.eval()\n","print(model(x))\n","print(model(x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73GkNqkZowis","executionInfo":{"status":"ok","timestamp":1748005500826,"user_tz":-540,"elapsed":13901,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"a90d75d1-3e16-475d-9bae-3ae96ed944d6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.1314,  0.8953,  0.5835,  ..., -0.1897,  0.0781,  0.4803],\n","        [ 0.4279,  0.1742,  0.1758,  ..., -0.1596,  0.6098,  1.0524]],\n","       grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3055,  0.2762,  0.5020,  ..., -0.1875,  0.5554, -0.5471],\n","        [ 0.5771, -0.2443,  0.5896,  ..., -0.3392,  1.3183, -0.2565]],\n","       grad_fn=<AddmmBackward0>)\n","tensor([[ 0.1682,  0.7888,  0.1625,  ..., -0.2031,  0.4773,  0.3328],\n","        [ 0.0449,  0.7178,  0.2955,  ..., -0.1545,  0.6339,  0.3092]],\n","       grad_fn=<AddmmBackward0>)\n","tensor([[ 0.1682,  0.7888,  0.1625,  ..., -0.2031,  0.4773,  0.3328],\n","        [ 0.0449,  0.7178,  0.2955,  ..., -0.1545,  0.6339,  0.3092]],\n","       grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["# F.pad 실험\n","input = torch.randn(1, 5, 5, 3) # 개행열채\n","pad_r = 2\n","pad_b = 1\n","output = F.pad(input, (0, 0, 0, pad_r, 0, pad_b))\n","# pad size 는 left right (열) top bottom (행) front back (채) 순인데 채행열로 들어온다고 생각하기 때문에 행열채로 되어있는 현재 상황을 잘 생각해줘야..\n","# 즉, front back lr tb 순이 된다!\n","\n","print(output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"So43r8xkaENS","executionInfo":{"status":"ok","timestamp":1748005500848,"user_tz":-540,"elapsed":21,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"c4532a53-7117-4f72-a4be-559c161206ea"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 21, 22, 3])\n"]}]},{"cell_type":"code","source":["# pad_r, pad_b 가 어떻게 계산되는건지\n","M0, M1 = [7,7]\n","W = 20\n","H = 20\n","pad_r = (M1 - W % M1) % M1\n","pad_b = (M0 - H % M0) % M0\n","print(pad_r)\n","print(pad_b)\n","\n","pad_r = (M1 - W % M1) # 배수 일 때는 pad=0 이여야 해서 마지막에 %M1 가 붙어야 함\n","pad_b = (M0 - H % M0)\n","print(pad_r)\n","print(pad_b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fS7CqglG9cN9","executionInfo":{"status":"ok","timestamp":1748005500862,"user_tz":-540,"elapsed":17,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"114ab629-3159-448a-b427-167cfa36abe4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1\n","1\n","1\n"]}]},{"cell_type":"code","source":["# torch.roll 실험\n","x = torch.randint(0,6, (1,5,5,1))\n","print(x.squeeze())\n","\n","shifted_x = torch.roll(x, shifts=(2, 0), dims=(1, 2)) # 아래로 두칸 이동\n","print(shifted_x.squeeze())\n","\n","shifted_x = torch.roll(x, shifts=(-2, 0), dims=(1, 2)) # 위로 두칸 이동\n","print(shifted_x.squeeze())\n","\n","shifted_x = torch.roll(x, shifts=(0, 2), dims=(1, 2)) # 오른쪽으로 두칸 이동\n","print(shifted_x.squeeze())\n","\n","shifted_x = torch.roll(x, shifts=(0, -2), dims=(1, 2)) # 왼쪽으로 두칸 이동\n","print(shifted_x.squeeze())\n","\n","shifted_x = torch.roll(x, shifts=(-2, -2), dims=(1, 2)) # 왼쪽 위로 두칸씩 이동\n","print(shifted_x.squeeze())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BZcgFiswcvm","executionInfo":{"status":"ok","timestamp":1748005500879,"user_tz":-540,"elapsed":15,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"42dd1da8-0871-4a21-ace4-af0fc2fede33"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[5, 4, 5, 4, 4],\n","        [4, 4, 0, 4, 4],\n","        [4, 2, 3, 2, 0],\n","        [3, 1, 5, 2, 1],\n","        [2, 3, 0, 4, 1]])\n","tensor([[3, 1, 5, 2, 1],\n","        [2, 3, 0, 4, 1],\n","        [5, 4, 5, 4, 4],\n","        [4, 4, 0, 4, 4],\n","        [4, 2, 3, 2, 0]])\n","tensor([[4, 2, 3, 2, 0],\n","        [3, 1, 5, 2, 1],\n","        [2, 3, 0, 4, 1],\n","        [5, 4, 5, 4, 4],\n","        [4, 4, 0, 4, 4]])\n","tensor([[4, 4, 5, 4, 5],\n","        [4, 4, 4, 4, 0],\n","        [2, 0, 4, 2, 3],\n","        [2, 1, 3, 1, 5],\n","        [4, 1, 2, 3, 0]])\n","tensor([[5, 4, 4, 5, 4],\n","        [0, 4, 4, 4, 4],\n","        [3, 2, 0, 4, 2],\n","        [5, 2, 1, 3, 1],\n","        [0, 4, 1, 2, 3]])\n","tensor([[3, 2, 0, 4, 2],\n","        [5, 2, 1, 3, 1],\n","        [0, 4, 1, 2, 3],\n","        [5, 4, 4, 5, 4],\n","        [0, 4, 4, 4, 4]])\n"]}]},{"cell_type":"code","source":["# 그룹 번호 매기기\n","M0, M1 = [7, 7]\n","shift_size = [3, 3]\n","H_pad = W_pad = 21\n","# num_windows = (H_pad // M0) * (W_pad // M1)\n","\n","window_group_num = torch.zeros(H_pad, W_pad)\n","h_slices = ((0, -M0), (-M0, -shift_size[0]), (-shift_size[0], None))\n","w_slices = ((0, -M1), (-M1, -shift_size[1]), (-shift_size[1], None))\n","count = 0\n","for h in h_slices:\n","    for w in w_slices:\n","        window_group_num[h[0] : h[1], w[0] : w[1]] = count\n","        count += 1\n","\n","print(window_group_num.shape)\n","plt.figure()\n","plt.imshow(window_group_num, cmap='gray')\n","plt.xticks(range(0,W_pad,2), range(1,W_pad+1,2))\n","plt.yticks(range(0,H_pad,2), range(1,H_pad+1,2))\n","plt.colorbar()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"id":"Z_GdpTkLJbcb","executionInfo":{"status":"ok","timestamp":1748005501241,"user_tz":-540,"elapsed":359,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"1627242d-e15e-4bca-8b5a-c407896f7bdc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([21, 21])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# 각 윈도우 별로(행) group number(열)가 적힌 행렬 만들기\n","window_group_num = rearrange(window_group_num, '(윈0 M0) (윈1 M1) -> (윈0 윈1) (M0 M1)', M0=M0, M1=M1) # 21x21 -> 9x49\n","print(window_group_num.shape)\n","print(window_group_num)\n","# attn_mask 만들기 (9개 윈도우 별로 행마다 우리조야 아니야? 우리조면 0 다른 조면 0 아닌 값을 쌓음)\n","attn_mask = window_group_num.unsqueeze(2) - window_group_num.unsqueeze(1)\n","print(attn_mask.shape)\n","attn_mask[attn_mask != 0] = -1e10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNRnJyp5PZ3G","executionInfo":{"status":"ok","timestamp":1748005501249,"user_tz":-540,"elapsed":42,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"00a74ca9-fd86-4a39-bcfa-7973c9be0ace"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([9, 49])\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1.,\n","         2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1.,\n","         1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1.,\n","         2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1.,\n","         1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2.],\n","        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n","         3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 6., 6., 6., 6., 6., 6., 6., 6.,\n","         6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n","        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n","         3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 6., 6., 6., 6., 6., 6., 6., 6.,\n","         6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n","        [4., 4., 4., 4., 5., 5., 5., 4., 4., 4., 4., 5., 5., 5., 4., 4., 4., 4.,\n","         5., 5., 5., 4., 4., 4., 4., 5., 5., 5., 7., 7., 7., 7., 8., 8., 8., 7.,\n","         7., 7., 7., 8., 8., 8., 7., 7., 7., 7., 8., 8., 8.]])\n","torch.Size([9, 49, 49])\n"]}]},{"cell_type":"code","source":["# 윗 셀에서 window_group_num.unsqueeze(2) - window_group_num.unsqueeze(1) 어떤 식으로 빼지는 건지 확인\n","window_group_num_test = torch.tensor([[0, 0, 0, 0], [1, 2, 1, 2], [3, 3, 6, 6], [4, 5, 7, 8]])\n","attn_mask_test = window_group_num_test.unsqueeze(2) - window_group_num_test.unsqueeze(1)\n","print(window_group_num_test)\n","print(window_group_num_test.unsqueeze(2))\n","print(window_group_num_test.unsqueeze(1))\n","print(attn_mask_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XV9LgIzFYuXp","executionInfo":{"status":"ok","timestamp":1748006089357,"user_tz":-540,"elapsed":24,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"29ed731b-205b-4b67-98d1-79e88410126f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 0, 0, 0],\n","        [1, 2, 1, 2],\n","        [3, 3, 6, 6],\n","        [4, 5, 7, 8]])\n","tensor([[[0],\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[1],\n","         [2],\n","         [1],\n","         [2]],\n","\n","        [[3],\n","         [3],\n","         [6],\n","         [6]],\n","\n","        [[4],\n","         [5],\n","         [7],\n","         [8]]])\n","tensor([[[0, 0, 0, 0]],\n","\n","        [[1, 2, 1, 2]],\n","\n","        [[3, 3, 6, 6]],\n","\n","        [[4, 5, 7, 8]]])\n","tensor([[[ 0,  0,  0,  0],\n","         [ 0,  0,  0,  0],\n","         [ 0,  0,  0,  0],\n","         [ 0,  0,  0,  0]],\n","\n","        [[ 0, -1,  0, -1],\n","         [ 1,  0,  1,  0],\n","         [ 0, -1,  0, -1],\n","         [ 1,  0,  1,  0]],\n","\n","        [[ 0,  0, -3, -3],\n","         [ 0,  0, -3, -3],\n","         [ 3,  3,  0,  0],\n","         [ 3,  3,  0,  0]],\n","\n","        [[ 0, -1, -3, -4],\n","         [ 1,  0, -2, -3],\n","         [ 3,  2,  0, -1],\n","         [ 4,  3,  1,  0]]])\n"]}]},{"cell_type":"code","source":["# 0~8 번째 윈도우까지 (한 픽셀 기준으로 나머지 49개 픽셀에 대해서 누구랑 attention 해야할 지가 하얗게 나온다 => 같은 조 애들에만 attention!)\n","plt.figure()\n","plt.imshow(attn_mask[8], cmap='gray')\n","plt.colorbar()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"MtJyJjePVKDI","executionInfo":{"status":"ok","timestamp":1748006553916,"user_tz":-540,"elapsed":188,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"34d65d9b-e15b-405f-e22e-dee8d94f9c17"},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# relative position bias 만들기\n","window_size = (7,7)\n","B_hat = nn.Parameter(torch.zeros(4, (2 * window_size[0] - 1), (2 * window_size[1] - 1))) # 4 는 num_heads가 올자리\n","nn.init.trunc_normal_(B_hat, std=0.02)\n","print(B_hat.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mr5KifsVkMer","executionInfo":{"status":"ok","timestamp":1748006908204,"user_tz":-540,"elapsed":66,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"cbe04252-7cb7-4a3e-af04-b0efe6fb816c"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 13, 13])\n"]}]},{"cell_type":"code","source":["coords_h = torch.arange(window_size[0])\n","coords_w = torch.arange(window_size[1])\n","\n","H, W = torch.meshgrid(coords_h, coords_w)\n","print(H)\n","print(W)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kg0w42KrkSQR","executionInfo":{"status":"ok","timestamp":1748006909129,"user_tz":-540,"elapsed":21,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"dcb27e93-10ae-4455-9bb1-7836c3e27441"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1],\n","        [2, 2, 2, 2, 2, 2, 2],\n","        [3, 3, 3, 3, 3, 3, 3],\n","        [4, 4, 4, 4, 4, 4, 4],\n","        [5, 5, 5, 5, 5, 5, 5],\n","        [6, 6, 6, 6, 6, 6, 6]])\n","tensor([[0, 1, 2, 3, 4, 5, 6],\n","        [0, 1, 2, 3, 4, 5, 6],\n","        [0, 1, 2, 3, 4, 5, 6],\n","        [0, 1, 2, 3, 4, 5, 6],\n","        [0, 1, 2, 3, 4, 5, 6],\n","        [0, 1, 2, 3, 4, 5, 6],\n","        [0, 1, 2, 3, 4, 5, 6]])\n"]}]},{"cell_type":"code","source":["# relative position bias 만들기 (continued)\n","relative_coords_h = H.reshape(1,-1) - H.reshape(-1,1)\n","relative_coords_w = W.reshape(1,-1) - W.reshape(-1,1)\n","\n","print(W.reshape(1,-1))\n","print(W.reshape(-1,1))\n","print(relative_coords_h)\n","print(relative_coords_w)\n","print(relative_coords_h.shape)\n","print(relative_coords_w.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkPV6Vzqkotk","executionInfo":{"status":"ok","timestamp":1748006910152,"user_tz":-540,"elapsed":25,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"ab06e48e-5163-4067-8cc7-83e8664f6f59"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2,\n","         3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5,\n","         6]])\n","tensor([[0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6]])\n","tensor([[ 0,  0,  0,  ...,  6,  6,  6],\n","        [ 0,  0,  0,  ...,  6,  6,  6],\n","        [ 0,  0,  0,  ...,  6,  6,  6],\n","        ...,\n","        [-6, -6, -6,  ...,  0,  0,  0],\n","        [-6, -6, -6,  ...,  0,  0,  0],\n","        [-6, -6, -6,  ...,  0,  0,  0]])\n","tensor([[ 0,  1,  2,  ...,  4,  5,  6],\n","        [-1,  0,  1,  ...,  3,  4,  5],\n","        [-2, -1,  0,  ...,  2,  3,  4],\n","        ...,\n","        [-4, -3, -2,  ...,  0,  1,  2],\n","        [-5, -4, -3,  ..., -1,  0,  1],\n","        [-6, -5, -4,  ..., -2, -1,  0]])\n","torch.Size([49, 49])\n","torch.Size([49, 49])\n"]}]},{"cell_type":"code","source":["# relative position bias 만들기 (continued)\n","relative_position_index_h = relative_coords_h + window_size[0] - 1 # 인덱스가 0부터 시작하도록 6을 더해줌 (즉, \"기준\"의 좌표는 (6,6)임)\n","relative_position_index_w = relative_coords_w + window_size[1] - 1\n","\n","print(relative_position_index_h)\n","print(relative_position_index_w)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjQ8Al6-mQ_0","executionInfo":{"status":"ok","timestamp":1748006911151,"user_tz":-540,"elapsed":26,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"8e3dce4b-b2f3-49c9-f77d-7f6729b64a6b"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 6,  6,  6,  ..., 12, 12, 12],\n","        [ 6,  6,  6,  ..., 12, 12, 12],\n","        [ 6,  6,  6,  ..., 12, 12, 12],\n","        ...,\n","        [ 0,  0,  0,  ...,  6,  6,  6],\n","        [ 0,  0,  0,  ...,  6,  6,  6],\n","        [ 0,  0,  0,  ...,  6,  6,  6]])\n","tensor([[ 6,  7,  8,  ..., 10, 11, 12],\n","        [ 5,  6,  7,  ...,  9, 10, 11],\n","        [ 4,  5,  6,  ...,  8,  9, 10],\n","        ...,\n","        [ 2,  3,  4,  ...,  6,  7,  8],\n","        [ 1,  2,  3,  ...,  5,  6,  7],\n","        [ 0,  1,  2,  ...,  4,  5,  6]])\n"]}]},{"cell_type":"code","source":["# relative position bias 만들기 (continued)\n","B = B_hat[:, relative_position_index_h, relative_position_index_w] # B_hat.shape = 헤(2M-1)(2M-1), B.shape = 헤단단\n","B = B.unsqueeze(0).unsqueeze(0) # 헤단단 -> 11헤단단, 이걸 개윈헤단단과 더하면 알아서 11->개윈으로 복제됨(broadcasting)\n","print(B_hat.shape)\n","print(B.shape) # 개윈헤단단 (데이터끼리, 윈도우끼리는 B가 다르지 않음. 헤드마다, 레이어마다 다름)\n","print(B)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfgCMsyQe5kA","executionInfo":{"status":"ok","timestamp":1748007065921,"user_tz":-540,"elapsed":8,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"92468e2a-410a-4584-d5f4-97081780121e"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 13, 13])\n","torch.Size([1, 1, 4, 49, 49])\n","tensor([[[[[ 0.0011, -0.0150, -0.0279,  ...,  0.0279, -0.0219, -0.0218],\n","           [-0.0268,  0.0011, -0.0150,  ...,  0.0149,  0.0279, -0.0219],\n","           [-0.0230, -0.0268,  0.0011,  ..., -0.0030,  0.0149,  0.0279],\n","           ...,\n","           [-0.0021,  0.0606, -0.0125,  ...,  0.0011, -0.0150, -0.0279],\n","           [ 0.0070, -0.0021,  0.0606,  ..., -0.0268,  0.0011, -0.0150],\n","           [-0.0272,  0.0070, -0.0021,  ..., -0.0230, -0.0268,  0.0011]],\n","\n","          [[-0.0182,  0.0110,  0.0067,  ...,  0.0031,  0.0223, -0.0012],\n","           [ 0.0022, -0.0182,  0.0110,  ..., -0.0332,  0.0031,  0.0223],\n","           [ 0.0028,  0.0022, -0.0182,  ...,  0.0220, -0.0332,  0.0031],\n","           ...,\n","           [ 0.0232, -0.0230,  0.0210,  ..., -0.0182,  0.0110,  0.0067],\n","           [-0.0445,  0.0232, -0.0230,  ...,  0.0022, -0.0182,  0.0110],\n","           [-0.0357, -0.0445,  0.0232,  ...,  0.0028,  0.0022, -0.0182]],\n","\n","          [[ 0.0260, -0.0211, -0.0049,  ..., -0.0395,  0.0019, -0.0168],\n","           [ 0.0247,  0.0260, -0.0211,  ..., -0.0251, -0.0395,  0.0019],\n","           [-0.0142,  0.0247,  0.0260,  ..., -0.0103, -0.0251, -0.0395],\n","           ...,\n","           [ 0.0155, -0.0200,  0.0030,  ...,  0.0260, -0.0211, -0.0049],\n","           [-0.0214,  0.0155, -0.0200,  ...,  0.0247,  0.0260, -0.0211],\n","           [-0.0065, -0.0214,  0.0155,  ..., -0.0142,  0.0247,  0.0260]],\n","\n","          [[-0.0048,  0.0563, -0.0270,  ..., -0.0101, -0.0045, -0.0235],\n","           [ 0.0012, -0.0048,  0.0563,  ..., -0.0143, -0.0101, -0.0045],\n","           [ 0.0038,  0.0012, -0.0048,  ...,  0.0274, -0.0143, -0.0101],\n","           ...,\n","           [-0.0091, -0.0015,  0.0049,  ..., -0.0048,  0.0563, -0.0270],\n","           [-0.0260, -0.0091, -0.0015,  ...,  0.0012, -0.0048,  0.0563],\n","           [-0.0043, -0.0260, -0.0091,  ...,  0.0038,  0.0012, -0.0048]]]]],\n","       grad_fn=<UnsqueezeBackward0>)\n"]}]},{"cell_type":"code","source":["# 인덱싱 방법 모음. 위 셀에서는 2-2 방식을 사용한 것 (속에 텐서 들어가도 됨)\n","A=torch.tensor([[1,2,6],[3,4,7],[5,6,2],[7,8,9]])\n","print(A)\n","print(A.shape)\n","\n","# 1. A[몇 번째 행이냐, 몇 번째 열이냐]\n","# print(A[0,1])\n","# 2-1. A[[몇 번째 행이냐,몇 번째 행이냐], [몇 번째 열이냐,몇 번째 열이냐]]\n","# print(A[ [0,2,3,1,2], [1,1,0,0,0] ])\n","# 2-2. A[ [[몇 번째 행이냐], [몇 번째 행이냐]], [[몇 번째 열이냐], [몇 번째 열이냐]] ] => 결과가 행렬 형태가 되도록 인덱싱!\n","print(A[  [[0, 2], [3, 1]],  [[0, 2], [1, 0]]  ])\n","# 3. A[ tensor(bool) ] => A와 같은 shape을 가지는 tensor형 bool이 어디에 True를 가지고 있냐\n","# print(A[ torch.tensor([[False,True,True],[False,False,False],[False,False,True],[False,True,False]]) ])\n","# print(A[A==2]) # 마스킹같은 걸 할 수 있음\n","# 4. A[몇 번째 값에 True가 있냐, 몇 번째 값에 True가 있냐]\n","# print(A[[True,False,False,False],[False,True,True]])\n","# 5. A[ tensor ] => 몇 번째 것을 어떻게 쌓을거냐\n","# print(A[ torch.tensor([1,1,2,2,2]) ])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZmYhWvbMT1S","executionInfo":{"status":"ok","timestamp":1748007119160,"user_tz":-540,"elapsed":36,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"c81bde75-fb0d-46bd-8cd0-5491a935dbb3"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2, 6],\n","        [3, 4, 7],\n","        [5, 6, 2],\n","        [7, 8, 9]])\n","torch.Size([4, 3])\n","tensor([[1, 2],\n","        [8, 3]])\n"]}]},{"cell_type":"code","source":["# B_hat 과 비교 확인\n","print(B[0,0,0,0,0]) # 개윈헤단단\n","print(B_hat[0,6,6]) # 헤단단, 자기 자신과 내적에 대한 bias는 B_hat의 6,6에 존재\n","\n","print(B[0,0,0,0,1])\n","print(B_hat[0,6,7]) # 한칸 오른쪽\n","\n","print(B[0,0,0,0,7]) # 맨 윗줄이 0~6 이므로 한 칸 아래는 7 번째\n","print(B_hat[0,7,6]) # 한 칸 아래는 B_hat의 7,6에 존재"],"metadata":{"id":"ILlbmha6gdgk","executionInfo":{"status":"ok","timestamp":1748005501534,"user_tz":-540,"elapsed":19,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3a3dcb4-f5d3-400c-eb5f-22bd81d0a83a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.0123, grad_fn=<SelectBackward0>)\n","tensor(0.0123, grad_fn=<SelectBackward0>)\n","tensor(-0.0199, grad_fn=<SelectBackward0>)\n","tensor(-0.0199, grad_fn=<SelectBackward0>)\n","tensor(0.0080, grad_fn=<SelectBackward0>)\n","tensor(0.0080, grad_fn=<SelectBackward0>)\n"]}]}]}